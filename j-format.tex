% SCIS 2021 原稿提出要領 (LaTeX用)
\documentclass{jarticle}
\usepackage[dvipdfmx]{graphicx}
\usepackage{comment}


\usepackage{scis2021j}
% LaTeX 2.09 を利用される場合，上記 2 行を消して下記 1 行のコメントアウ
% トを外してください．
%\documentstyle[scis2021j]{jarticle}

\begin{document}

\title{
  プロセッサへの実装に向けたORAMにおけるポジションマップ削減手法の検討\\
  Reducing a position map size of Oblivious RAM for implementing on microprocessors
}



\author{
  山方　大輔
  \thanks{
    九州大学　システム情報科学府　情報知能工学専攻 %
    〒819--0395 福岡県西区元岡744番地.  %
    SCIS 2021 Secretariat,
    1, Motooka, Nishi-ku, Fukuoka-shi, Fukuoka 819--0395, Japan. %
    isec-scis2021@ieice.org}\\
  Daisuke Yamagata
  \and
  川上　哲志
  \thanks{
    九州大学大学院システム情報科学研究院}\\
  Satoshi Kawakami
  \and
  谷本　輝夫
  \thanks{
    九州大学情報基盤研究開発センター}\\
  Teruo Tanimoto
  \and
  井上　弘士
  \thanks{
    九州大学大学院システム情報科学研究院}\\
  Koji Inoue
  \and
　小野　貴継
  \thanks{
    九州大学大学院システム情報科学研究院}\\
  Takatsugu Ono
}


\abstract*{ % 日本語あらまし
 プロセッサから主記憶に対するアクセス情報（アドレス等）を秘匿する技術としてPath Oblivious RAM (ORAM)が挙げられる．PathORAMの実用化にあたり，アドレスを秘匿化するために必要なポジションマップと呼ばれる機構のサイズが大きくチップへの実装が困難という課題がある．既存技術として階層PathORAMと呼ばれる技術があり，これは面積問題を解決する一方，性能を大幅に低下させる問題がある．
　この問題を解決するために，階層PathORAMとは異なるポジションマップ削減手法を検討する．ポジションマップはデータがメモリ上のどのアドレスに格納されるかを管理している．PathORAMでは1つのデータに対し1つの格納場所を保持する．検討手法は複数のデータに対して格納場所を保持することで，ポジションマップのサイズを削減する．
 この手法はPathORAMとデータの格納方法が異なり，面積，性能やセキュリティの面から総合的に検討する必要がある．
 本稿では，SPEC2006のベンチマークで実験し，ベンチマーク特性を調査した．
　対象としたベンチマークにおいて，検討手法はPathORAMに比べて，性能低下を招くことなくポジションマップのサイズを75％削減可能であることを確認した．
}
\keywords*{ %日本語キーワード
  ハードウェアセキュリティ，PathORAM，サイドチャネル攻撃}

\maketitle

\section{はじめに}
 計算機を対象に，サイドチャネル攻撃など情報を窃取する手法が多く提案されており，機密データが窃取される危険にさらされている．攻撃者によるデータの盗み見や改ざんを防ぐために，主記憶に格納するデータは暗号化により保護する手法が考えられる．しかしながら，データの暗号化のみではデータが十分に秘匿されないことが指摘されている[2]．特に，メモリのアクセスパターンを観察することで，データ漏洩の危険があることが報告されている[1]．ここで，アクセスパターンは，アクセスされたアドレスを含むアクセスに関する情報を指す．

%アクセスパターンの秘匿を考慮しない場合，メモリアクセスの際に読み込むデータは要求されたデータのみである．
%PathORAMでは，メモリアクセスの際に読み込むデータは要求されたデータを含む複数のデータである．
アクセスパターンを秘匿する代表的な技術として，PathORAMが挙げられる[3]．
アクセスパターンの秘匿を考慮しない場合，メモリアクセスの際に読み込むデータは要求されたデータのみである．
PathORAMでは，メモリアクセスの際に読み込むデータは要求されたデータを含む複数のデータである．
%PathORAMではメモリアクセスのたびに要求されたデータを含む複数の冗長なデータの読み込みを行う．
これにより，攻撃者は一連のメモリアクセスにおいて，要求されたデータを判別することは不可能である．
また，PathORAMは要求されたデータの格納位置をアクセスのたびに変更することでアクセスパターンを秘匿する手法である．
一方で，PathORAMは追加のハードウェアや冗長なメモリアクセスを必要とすることから，実装面積の増加や性能低下，消費エネルギーの増大などのオーバーヘッドが生じる．特に，PathORAM の機能を実現するにあたり，追加のハードウェアの一つであるポジションマップのサイズの大きさが課題である．

既存技術として階層PathORAMと呼ばれる技術があり，この技術は面積問題を解決する一方，性能を大幅に低下させるという問題がある.
そこで本稿では，階層PathORAMではないポジションマップサイズを削減する手段が性能や面積に与える影響を調査した．

ポジションマップはデータがメモリ上のどのアドレスに格納されるかを管理している.PathORAMでは1つのデータに対し1つの格納場所を保持する.
本稿で検討するポジションマップサイズを削減する手段は，複数のデータに対して格納場所を保持することで，ポジションマップのサイズを削減する. 

このポジションマップ削減方式は，PathORAM独自のハードウェアサイズに影響を与える．
その上，そのハードウェアのサイズは性能に影響を与える．
加えて，データの格納方法もPathORAMとは異なるため，セキュリティの検討も必要となる．
このことから，この方式については面積，性能やセキュリティの検討などを総合的に行う必要がある．
そこで，ひとまず本稿ではSPEC2006のベンチマークで評価を行い，このベンチマークごとにそれぞれどのような特性があるか調査した．

%脅威モデル
我々の脅威モデルでは先行研究[3]と同様に，セキュアなマイクロプロセッサでプログラムを実行することとする．
プロセッサ内部のすべてのデータは外部からは見えないものとし，プロセッサは外部の信用できない主記憶と信用できないメモリバスを通じてやり取りを行う．
プロセッサ外のすべてのメモリバスで運ばれるデータはすべて攻撃者にさらされるものとする．そのため，データの内容自体に加えてデータのアクセスパターンも保護する必要がある．
本稿ではデータは全て暗号化して取り扱われているものとする．

データの内容はデータ暗号化により保護される一方で，メモリアクセスパターンは秘密情報を漏洩する危険が存在する．
主記憶のアクセスパターンの秘匿に関して様々な先行研究[4][5]が存在する．
本稿も同様に，データ暗号化ではなく主記憶アクセスパターンの秘匿に焦点を当てる．
%本稿では，ORAM設計において幅広く議論されている主記憶アドレスのアクセスパターンの秘匿に焦点を当てている[4][5]．
その他の攻撃については本稿では範囲外とする．

%リーフラベル共有手法と評価結果　
ポジションマップのサイズを削減する手段として，本研究では複数のアドレスで一つのリーフラベルを共有する手法が与える影響を検討した．
この手法はアドレスをあるハッシュ関数に入力として渡すことでハッシュ値を算出し，その値とリーフラベルを紐付けることで従来のPathORAM と同様の動作を行う．
ハッシュ値が同値となるアドレスが同じリーフラベルを共有することで，ポジションマップサイズを削減する．
加えて，ポジションマップのサイズを削減することにより，ポジションマップにおけるPathORAMの実装に伴う消費エネルギーや実行時間の削減が期待できる．
%定量的な評価の結果，検討した方式は，対象としたベンチマークにおいて性能低下を招くことなくポジションマップのサイズを75％以上削減可能であることを確認した．
定量的な評価の結果，検討した方式は，
対象としたベンチマークにおいてポジションマップのサイズを75％削減した場合においても性能低下を招かないことを確認した．

%定量的な評価の結果，提案手法は従来手法に比べて，性能低下を招くことなくポジションマップのサイズを75％以上削減可能であることを確認した．


%本稿では，第2節でPathORAMについて述べ，第3節で提案手法について述べ，第4節で提案手法の評価を述べ，第4節ではまとめと今後の研究方針を述べる．


\section{PathORAMの概要と実装方法}
\subsection{概要}
　%主記憶アクセスパターンを秘匿する代表的な手法のひとつとして，PathORAM が挙げられる．そこで本節では， PathORAM について紹介する．PathORAMでは，主記憶アクセスのたびに要求されたデータを含む複数のデータの読み込みを行う．これにより，攻撃者に一連のメモリアクセス内で要求されたデータを判別されることを防ぐ．一方で，PathORAMはメモリリクエストのたびに複数のメモリアクセスが発生するため，大幅な性能の低下や消費エネルギーが増加するという問題がある．
本節では， PathORAM について紹介する．
PathORAMでは，主記憶アクセスのたびに要求されたデータを含む複数のデータの読み込みを行う．
加えて，アクセスのたびに要求されたデータの格納位置はランダムに変更する．
これにより，攻撃者に一連のメモリアクセス内で要求されたデータを判別されることを防ぐ．
一方で，PathORAMはメモリリクエストのたびに複数のメモリアクセスが発生するため，大幅な性能の低下や消費エネルギーが増加する問題がある．

\subsection{構成}
　PathORAM では，プログラムアドレス，データ，リーフラベル（後述）の３個の組からなるデータブロックを一つの単位としてデータを取り扱う．
プログラムアドレスは各データブロックの識別を行うために用いられる．
PathORAM は，外部メモリとORAM コントローラ(オンチップ) から構成される．
外部メモリでは，データは木構造を用いて保持され，この木をパスツリーと呼ぶ．
パスツリーの高さがHのとき，根ノードの高さをLevel 0とし，葉ノードの高さはLevel H-1とする．
各ノードには複数のデータブロックが記憶され，このノードをバケットと呼ぶ．
葉ノードは図１のパスツリー部分に示すようにそれぞれ左から順に番号付けられ，この番号をリーフラベルと呼ぶ．
また，根ノードから葉ノードまでの経路をパスと呼ぶ．
ここで，各データブロックはブロック内に保持するリーフラベルのパス上もしくはスタッシュ（後述）内にそのデータブロックは格納されなければならない．
ORAMコントローラはポジションマップとスタッシュに加えて，これらを制御するための回路から構成される．
ポジションマップは各データのアドレスを入力とし，そのデータが存在するパスのリーフラベルを出力とするルックアップテーブルである．
これにより，各データがパスツリーのどのパス上に存在するかを記憶する．
スタッシュは一時的にデータブロックを複数保持できる記憶領域である．
スタッシュの特徴はアドレスをインデックスとしてデータブロックを参照できることである．

\begin{figure}[t]
  \includegraphics[width=8.0cm]{saa.png}
  \caption{PathORAMアーキテクチャ}
  \label{tree}
\end{figure}

\subsection{メモリアクセス}
　本節では，PathORAM適用時のメモリアクセス手順を述べる(図１)．例として，アドレスuのメモリリクエ
ストを示す．本稿では，以降PathORAMにおけるメモリアクセスをORAMアクセスと定義する．

\begin{enumerate}
  \item 	スタッシュ内でアドレスuを保持するデータブロックを探索し，存在した場合はLast Level Cache (LLC)に転送する．スタッシュにデータが存在しなければ，手順２を実行する．

  \item 	アドレスuを入力として，ポジションマップを検索し，アドレスuに対応したリーフラベルlを参照する．そして，そのアドレスに紐付けられたリーフラベルをランダムに変更する(リーフラベルl’)．

  \item 	パスl上にあるデータブロックをすべて外部メモリ(パスツリー)からスタッシュに格納する．（本稿では，この操作をパス読み込みと定義する．）その後，要求されたアドレスのデータブロックをLCCに転送する．

  \item 	リーフラベルを参照し，スタッシュ内のデータブロックを可能な限り多くパスl上に書き戻す．また，書き戻せないノードにはダミーのデータの書き込みを行う．（本稿では，この操作をパス書き込みと定義する．）

\end{enumerate}

\subsection{スタッシュオーバーフロー}
第2.2節で述べたように，各データブロックは自身が保有するリーフラベルのパス上もしくはスタッシュに書き込む必要がある．
この仕様から，パス書き込みにおいてパスツリーのパス上のノードにデータブロックを格納できないことがある．
PathORAM のパス書き込みでパスツリーに書き込むことができないデータはそのままスタッシュに保持される．
そのため，スタッシュにデータが蓄積し，スタッシュでデータがオーバーフローする危険性がある．
スタッシュオーバーフローした場合，データが消失するためプログラムが正しく実行しない．
スタッシュオーバーフローを防止するには，スタッシュサイズをオーバーフローしないサイズに設定する方法とスタッシュからデータをパスに書き戻す動作を加える方法がある．
後者の手法は、スタッシュサイズがしきい値に達したときスタッシュからメモリにデータを書き戻す動作を従来のPathORAM の動作に加える手法である（以下，本稿ではスタッシュ書き戻し動作と呼ぶこととする）．
しかしながら、この手法は通常のPathORAM よりもメモリアクセスが増加するため，消費エネルギーや実行時間が増大する．そのため，後者の手法であってもスタッシュサイズを慎重に選択する必要がある．
本稿では，後者の手法を適用する．

\subsection{セキュリティの証明}

　PathORAMのセキュリティ要件では，あるプログラムyとプログラムｚがそれぞれプログラム実行中にCPUが発行するデータ要求数が同じ時にプログラムyでアクセスされる一連のパスとプログラムzでアクセスされる一連のパスが計算上判別不可能であることとされている[6].
PathORAMではアクセスのたびに各データのリーフラベルがランダムに更新されるため，プログラム実行中にアクセスするパスがそれ以降にアクセスするパスと独立である．
それにより，プログラム実行中にアクセスする１連のパスが１意に決まる確率は$(\frac{1}{2^L})^M$となる(CPUが発行するデータ要求数をM，パスツリーの高さをLとする．)．
この確率は非常に小さい確率であるため，アクセスする1連のパスはランダムなビット列と計算で判別不可能であると考えられる．

\subsection{階層PathORAM}
PathORAMの重要な構成要素のひとつであるポジションマップはパスツリーのデータブロックのすべてのアドレスに対してリーフラベルを保持する必要がある
(ポジションマップサイズはパスツリーの総データブロック数に比例する)．
これにより，ポジションマップのサイズが大きく，チップ内に実装することが困難である．
この問題を解決する技術として，階層PathORAMと呼ばれる技術が提案されている．
%階層PathORAMはポジションマップを複数のパスツリーを用いて階層化し格納する技術である．
階層PathORAMは複数のパスツリーを追加して，ポジションマップを入れ子式に格納する手法である．

本稿では，階層の最初のパスツリーの一つをORAM0と呼ぶこととする．
このORAM0のポジションマップは２つ目のパスツリーORAM1に格納する．
これを繰り返すことによりパスツリーを縮小する(図2)．
ポジションマップサイズはパスツリーのデータブロック数に比例し，縮小されたORAMHのデータブロック数は削減されることから，ORAMHのポジションマップサイズは削減される．
階層PathORAMのORAM0からORAM(H-1)のポジションマップはそれぞれ次のパスツリーに保持される．
PathORAMではORAM0のポジションマップをCPUチップ上に保持する必要があるが，階層PathORAMではORAMHのポジションマップを保持すれば良い．
%これを繰り返すことによりパスツリーを縮小させ，チップ上に格納するべきポジションマップのサイズの縮小が可能となる．
H階層のPathORAMでは，ORAM0のデータにアクセスを行う手順は，まずORAMHのポジションマップを参照し，ORAMH，ORAM(H-1)，・・・，ORAM0の順でアクセスが実行される．
PathORAMのメモリアクセスはORAM0に対してのみのアクセスであるが，階層PathORAMのメモリアクセスはORAM0からORAMH全てに
アクセスするため，メモリアクセスするデータ数が増大する．

\begin{figure}[t]
  \begin{center}
  \includegraphics[width=8.0cm]{men.png}
  \caption{階層PathORAM}
  \label{tredsass}
  \end{center}
\end{figure}

%---------------------------------------------
\section{ポジションマップ削減手法の提案}
\subsection{リーフラベル共有によるポジションマップの削減}
　PathORAM には特性上，性能の低下，消費エネルギーの増大といったオーバーヘッドが存在する．
 %また，ポジションマップのサイズがCPUチップに実装するには大きいことが課題として挙げられる．
 また，CPUチップに実装するにはポジションマップのサイズが大きいことが課題として挙げられる．
 %本節ではポジションマップサイズを削減するリーフラベル共有手法を提案する．
 こ第2.6節で述べた階層PathORAMは面積問題を解決する一方で，性能が大幅に低下する．
 本節ではポジションマップサイズを削減するリーフラベル共有手法を提案する．
 これにより，性能低下を招くことなくPathORAMの面積問題の解決を目指す．

 従来のPathORAMではアドレスに対して固有のリーフラベルが割り当てられるのに対し，
 本手法では複数のアドレスでリーフラベルを共有する（本稿ではリーフラベルを共有するアドレスの数を共有数として定義する）．

  提案手法では，式(\ref{laa})に示すハッシュ関数を用いてリーフラベルを共有するアドレスを決定する．
このハッシュ関数に入力としてアドレスを渡し，出力されるハッシュ値が同値となるアドレスでリーフラベルを共有する．
(パスツリーのデータブロック総数をN，共有数をXとする．)
\begin{equation}
  ハッシュ値=(アドレス_{10}) mod (N/X)．
  \label{laa}
\end{equation}

%ポジションマップサイズ
　PathORAMのポジションマップサイズはすべてのデータブロックのアドレスに対してリーフラベルを記憶することから，$N×L$ビット必要となる(Nは総データブロック数，Lはパスツリーの高さとする)．
提案手法のポジションマップサイズはハッシュ値とリーフラベルを紐付けて記憶する．
これによりハッシュ値の総数はデータブロック総数の共有数分の1であることから，
提案手法で必要なポジションマップサイズは$(N/X)×L$ビットとなる．
提案手法ではポジションマップサイズを従来のPathORAMと比較して1/X倍に削減可能となる．

\subsection{動作}
　本節では，リーフラベル共有手法適用時のメモリアクセス手順を述べる(第2.3節と同様のパラメータを用いて述べる)．
提案手法では従来のORAMコントローラにハッシュ関数用の回路を追加して実装する(図3)．


\begin{enumerate}
  \item 	スタッシュ内でアドレスuを保持するデータブロックを探索し，存在した場合はLast Level Cache (LLC)に転送する．スタッシュにデータが存在しなければ，手順２を実行する．

  %\item 	アドレスuをハッシュ関数(式\ref{laa})に渡して，ハッシュ値hの計算を行う．ハッシュ値hを入力として，ポジションマップを検索し，ハッシュ値hに対応したリーフラベルlを参照する．そして，そのハッシュ値hに紐付けられたリーフラベルをランダムに変更する(リーフラベルl’)．
  \item 	既存手法ではポジションマップにアドレスを入力として渡すが，提案手法ではハッシュ値を入力として渡す．提案手法ではアドレスuをハッシュ値hに変換する必要があるため，まずアドレスuを式(\ref{laa})に示すハッシュ関数に渡し，ハッシュ値hの計算を行う．その後，ハッシュ値hを入力として，ポジションマップを検索し，ハッシュ値hに対応したリーフラベルlを参照する．そして，そのハッシュ値hに紐付けられたリーフラベルをランダムに変更する(リーフラベルl’)．

  \item 	既存手法と同様に，パスl上にあるデータブロックをすべて外部メモリからスタッシュに格納する(パス読み込み)．既存手法ではCPUから要求されたデータブロックのみリーフラベルを更新する一方，提案手法では複数のデータブロックでリーフラベルを共有するため，スタッシュ内にあるデータブロックで同じハッシュ値を持つブロックすべてのリーフラベルをl’に更新する．その後，要求されたアドレスのデータブロックをLCCに転送する．

  \item 	既存手法と同様に，リーフラベルを参照し，スタッシュ内のデータブロックを可能な限り多くパスl上に書き戻し，書き戻せないノードにはダミーのデータの書き込みを行う(パス書き込み)．
  

\end{enumerate}


\begin{figure}[t]
  \includegraphics[width=8.0cm]{saxz.png}
  \caption{リーフラベル共有手法アーキテクチャ}
  \label{treesa}
\end{figure}

\subsection{特徴}
　提案手法では同じハッシュ値を保持するアドレスは常にリーフラベルを共有する必要がある．
%
そのため，パス読み込みの際にはCPU から要求されたアドレスのデータブロックかつそのアドレスと同じリーフラベルを共有するアドレスのデータブロックのリーフラベルも新しいリーフラベルに更新する．
それにより提案手法は従来のPathORAM と比較してスタッシュにデータが蓄積しやすい特徴をもつ．
共有数が大きいほど，スタッシュにデータがより蓄積しやすくなる．
第2.4節から，提案手法は従来のPathORAMと比較してスタッシュオーバーフローが発生しやすい．
これによりスタッシュ書き戻し動作回数が増加することによりメモリアクセス数が増加し，性能低下に寄与する．

　一方で，提案手法は従来のPathORAMと比較してスタッシュにデータが蓄積しやすい特徴から，
CPUから要求されるデータがスタッシュ内に存在する確率が増加し，スタッシュヒット率が向上する可能性が存在する．
第3.1節から，スタッシュヒットが発生した場合，メモリアクセスが発生しないため，性能向上に寄与する．

%データブロックサイズ増加
　提案手法と同様にポジションマップサイズを削減する方法として，
データブロックサイズを増加して1つのデータブロックに複数のデータを保持し，同じリーフラベルを共有する実装が考えられる．
従来のPathORAMのデータブロックは，リーフラベル，アドレス，データの組からなるが，
上記の実装方法のデータブロックは，リーフラベル，アドレス，データ1，データ2，・・・，データn(n＞＝2)の組からなり，１つのデータブロックに複数のデータを保持する．
これにより，この実装では記憶すべきリーフラベル数が従来のPathORAMと比較して，$\frac{1}{n}$に削減されることから，ポジションマップサイズも同様に$\frac{1}{n}$に削減可能となる．



%セキュリティ
%第2.5節からPathORAMのセキュリティ要件を満たすためには，現在アクセスするパスが以降にアクセスするパスと独立であればよい．
%リーフラベル共有手法はアクセスのたびに，リーフラベルを共有するすべてのアドレスでリーフラベル更新が行われるため，
%現在アクセスするパスが以降にアクセスするパスと独立である．
%そのため，リーフラベル共有手法は従来の PathORAM と同様にアクセスパターンを秘匿することが可能である.
%一方で，パス読み込みのたびに複数のアドレスでリーフラベルを更新するため，データの格納位置が偏る．
%攻撃者に提案手法の適用を認知されている場合，パスツリーのデータが書き込める位置が攻撃者に漏洩する危険性が存在する．
%本手法は従来のPathORAM同様にアクセスパターンを秘匿する一方，同等のセキュリティレベルではない．


%かしながら，本手法が従来のPathORAM同様にアクセスパターンを秘匿されることは，攻撃者側から観察した場合のみである．
%一方で，アクセスパターンを設計者側から観察した場合，パス読み込みのたびに複数のアドレスでリーフラベルを更新するため，データの格納位置が偏ることが認識される．
%アクセスする１連のパスが１意に決まる確率は複数のアドレスで同じリーフラベルを共有することから従来のPathORAMとは異なる．
%そのため，本手法は従来のPathORAM同様にアクセスパターンを秘匿する一方，同等のセキュリティレベルではない．


\section{評価}
\subsection{手順}
%4.2
　第3.1節から，本稿で検討するポジションマップ削減方式はスタッシュにデータが蓄積しやすい特徴を持つ．
しかしながら，共有数を変更したとき，スタッシュにどの程度データが実際に蓄積するか明らかになっていない．
そこで，各共有数でスタッシュに蓄積するデータを調査した．
%4.3/
スタッシュ書き戻し動作の発生はメモリアクセスの増加に繋がり，性能低下を引き起こす．
そこで，性能低下を引き起こさず削減可能なポジションマップサイズを第4.3節で見積もった．
%4.4
%提案手法と同様にポジションマップサイズを削減する方法として，データブロックサイズを増加して１つのデータブロックに複数のデータを保持しデータブロック内で同じリーフラベルを共有する実装が考えられる．
本稿の検討方式と3.3節で述べたブロックサイズを増加する実装方法でメモリアクセス数に
どのような違いがあるか第4.4節で検討した．

 実験環境を表1に示した．
 提案手法において，データブロックサイズは64バイトで実験した．
 先行研究を参考にポジションマップサイズは92メガバイトとした[3]．
 %DRAM利用率は50%として実験した(2GBのORAMでは4GBのDRAMを必要とする)
 先行研究と比較するため，SPEC2006のプログラムで実験した[3][7]．
 階層PathORAMの性能改善に関する先行研究[7]を参考に，性能向上で差が生じたh264ref，hmmer，libquantum，omnetpp，gccの5つのワークロードを選択した．
 
 先行研究[7]により，階層PathORAMはPathORAMに比べ，主記憶アクセス数が2倍に増加することがわかった．
提案手法の目的は性能を維持しつつ，ポジションマップを削減することであり，
提案手法の適用によりメモリアクセス数が2倍以上となる結果は望ましくない．
そこで，実験時間も考慮して，メモリアクセス数が2倍に増加した時点で実験が終了するように設計した．


\begin{small}
\begin{table}
  \centering
    %\leavevmode
    \caption{仕様}
    \begin{tabular}{|l|c|} \hline
      core Type & In-order single-core x86 \\
      core frequency & 1Ghz \\
      L1 I/Dcache & 32KB/32KB,2-way,LRU \\
      L2cache & 1MB,8-way,LRU \\
      DRAM capacity & 4GB \\
      DRAM utilization & 50％ \\
      bucket size & 4 \\ \hline
    \end{tabular}
    \label{tab:const}
\end{table}
\end{small}

\subsection{スタッシュオーバーフロー}
 本稿のポジションマップを削減する検討方式は共有数によりスタッシュに蓄積するデータが増加する．
 本稿では，スタッシュサイズを無限大とし，検討方式の共有数を変更した際にスタッシュに最大でどの程度データが蓄積するか調査した．
共有数が4以下の場合，すべてのプログラムでスタッシュに256キロバイト以上蓄積しないことがわかった．
このことから，共有数が4以下においてスタッシュサイズを256キロバイトとした場合，
スタッシュ書き戻し動作は発生しないことがわかった．
先行研究[3]から，階層PathORAMにおけるポジションマップサイズは77キロバイトで実装される．
このことから，スタッシュサイズを256キロバイトとすることは現実的に実装可能な範囲であると考える．
そこで，4.2節ではスタッシュサイズを256キロバイトとして実験した．

\begin{figure}[t]
  \includegraphics[width=8.0cm]{sohu.png}
  \caption{各共有数における提案手法でのメモリアクセス数(gcc)}
  \label{gccres}
\end{figure}


\subsection{ポジションマップサイズ削減率}

検討方式はスタッシュ書き戻し動作が発生しやすい特徴を持つ．
この動作の発生はメモリアクセス数の増加につながることから性能低下を引き起こす．
そこで検討方式が共有数を変更することによりメモリアクセス数にどのような影響があるか調査した．
%そこでスタッシュ書き戻し動作による性能低下を招くことなくポジションマップがどの程度削減可能か調査した．
%共有数が大きいほどスタッシュにデータが蓄積しやすいため，スタッシュ書き戻し動作が発生しやすい．
従来のPathORAMと検討方式で共有数がそれぞれ1(従来のPathORAM)，2，4，8，16，32のとき，各プログラムの実行で発生する総メモリアクセス数を調査した．
%スタッシュにどの程度データが蓄積するかを調査し，提案手法によるスタッシュサイズの増加分を明らかにした．
各プログラムごとに総メモリアクセス数を共有数1で正規化した結果を図4に示す．

%
h264ref，libquantum，hmmer，omnetppのプログラムではすべての共有数においてメモリアクセスの増加はほとんど発生しなかった．
このことから，この4つのプログラムでは性能低下を招くことなく，ポジションマップを96.9％削減可能である．
gccでは共有数が8以上のとき従来のPathORAMと比較して，メモリアクセス数の増加が発生した．
このことから，gccでは性能低下を招くことなく，ポジションマップを75.0％削減可能であることがわかった．

%h264ref，libquantumのプログラムではすべての共有数で設定した場合も性能低下は発生しなかった．
%この2つのプログラムでは性能低下を招くことなく，ポジションマップを96.9％削減可能である．
%hmmer，omnetppのプログラムでは共有数は32が場合のみ性能低下が発生した．
%この2つのプログラムでは性能低下を招くことなく，ポジションマップを93.8％削減可能である．
%gccのプログラムでは共有数が8以上のとき性能低下が発生した．
%このプログラムでは性能低下を招くことなく，ポジションマップを75.0％削減可能であることがわかった．

\begin{figure}[t]
  \begin{center}
  \includegraphics[width=8.0cm]{kore.png}
  \caption{各共有数におけるメモリアクセス数}
  \label{tredss}
  \end{center}
\end{figure}

\subsection{ポジションマップ削減手法の比較}
%ポジションマップサイズを削減する方法として，検討方式とは別にデータブロックサイズを増加し，複数のデータで同じリーフラベルを共有する実装が考えられる．
検討方式とデータブロックサイズを増加する実装方法の総メモリアクセス数をそれぞれ調査した．
総メモリアクセスはスタッシュ書き戻し動作のよるメモリアクセス数の増加とスタッシュ書き戻し動作ではない操作によるメモリアクセス数
の和からスタッシュヒットにより削減されるメモリアクセス数を引いて算出した．
実験では，従来のPathORAM，リーフラベル共有数(X=2)，データブロックサイズ2倍(ブロックサイズ128バイト)，リーフラベル共有数(X=4)，データブロックサイズ4倍(ブロックサイズ256バイト)の各場合で評価を行った．
データブロックサイズ2倍の実装では，データブロックあたりに2つのデータを格納し1つのリーフラベルを共有し，ポジションマップサイズを$\frac{1}{2}$に削減する．
データブロックサイズ4倍の実装では，データブロックあたりに4つのデータを格納し1つのリーフラベルを共有し，ポジションマップサイズを$\frac{1}{4}$に削減する．
%各プログラムの実験結果を図5から図9に示す．


gccを除くプログラムでは，スタッシュ書き戻し動作が発生せず，各実装方法でメモリアクセス数に大きな変化は観察されなかった．
gccのプログラムでは，ブロックサイズを2倍にする実装の場合，スタッシュサイズが512KB以下において，
既存手法と比較して2倍のメモリアクセス数が発生した(図5)．
ブロックサイズを4倍にする実装の場合，スタッシュサイズが8MB以下では，既存手法と比較して2倍のメモリアクセス数が発生した．
ブロックサイズを増加する実装方法は，提案手法と比較してスタッシュ書き戻し動作の発生回数が増加したことから，
メモリアクセス数が増加した．
メモリアクセス数の増加は性能低下につながることから，
%スタッシュサイズを十分に確保できない場合，提案手法がブロックサイズを増加する実装方法と比較して適していることがわかった．
ブロックサイズを増加する実装方法は，性能低下の危険がある．
そのため，スタッシュサイズを十分に確保できない場合，検討方式を選択することが無難であると考える．

%ブロックサイズを増加する実装方法は，スタッシュサイズを十分に確保できない場合
%スタッシュ書き戻し動作の発生回数が増加により，メモリアクセス数が増加し，性能低下することがわかった．

%%
%一方で，スタッシュサイズが16MB以上のときメモリアクセス数が既存手法の$\frac{1}{4}$となった．
%gccのプログラムではデータの再利用性が高く，スタッシュヒット率が向上した．
%このことから，スタッシュサイズを十分に確保可能かつデータの再利用性が高いプログラムを実行する場合は，性能向上が見込めることがわかった．
%一方で，スタッシュサイズが十分に確保できない場合，リーフラベル共有手法がデータブロックサイズを増加する実装と比較して適していることがわかった．

\begin{figure}[t]
  \includegraphics[width=8.0cm]{asx.png}
  \caption{各共有数における提案手法でのメモリアクセス数(gcc)}
  \label{gccres}
\end{figure}



\section{おわりに}
　%検討手法によりポジションマップサイズを削減できることがわかった．
%一方で，この手法はスタッシュにデータが蓄積しやすくなることから必要なスタッシュサイズが増加する．
%これによりスタッシュ書き戻し動作回数が増加し，性能低下を引き起こす懸念がある．

%そこで，今後はスタッシュ書き戻し動作の発生を抑制するために，スタッシュに蓄積するデータブロック数が少ない実装を目指す．
%加えて，従来のPathORAMと同等のセキュリティを保持しつつポジションマップサイズを削減する手法の探索を行う．



　従来のPathORAMではポジションマップサイズが大きく実際のマイクロプロセッサへの実装が困難であった．そこで，複数のアドレスでリーフラベルを共有することでポジションマップサイズを削減するリーフラベル共有手段を検討した．
スタッシュサイズを256KBとしたとき，検討手法はPathORAMに比べて，
対象としたベンチマークでは性能低下を招くことなくポジションマップが75％削減可能であることが明らかになった．
また，マイクロプロセッサにPathORAMを適用する上で，CPUチップ上に実装されるスタッシュサイズは可能な限り小さく設計することが求められるため，
データブロックサイズを増加する実装と比較して，検討手法の適用が無難であることがわかった．
今後は，検討手法のセキュリティも含めて研究を行う．

\section{謝辞}
本研究は一部，JSPS科研費JP19K20235の助成による研究が遂行されたものです．
この場を借りて深く御礼申し上げます．

\begin{tabular}{l}
%[
%SCIS 2021 事務局 \\
%Email: \texttt{isec-scis2021@mail.ieice.org} \\
\end{tabular}

%\section{参考文献}
%\bibliographystyle{jplain}
%\bibliography{ref.bib}

%\noindent[1]Mohmmad Saiful Islam, Mehmet Kuzu and Murat Kantarcioglu,”Access Pattern disclosure on Searchable Encryption:Ramification,Attack and Mitigation,”In Proc. of the 19th Network and Distributed System Security Symposium,2012.

%\noindent[2]Benny Pinkas and Tzachy Reinman,"Oblivious RAM Revisited,"  In Proc. of the 30th Annual cryptography conference, pp.  502-519, 2010.

%\noindent[3]Ling Ren, Xiangyao yu, Christopher W. Fletcher, Marten van Dijk and Srinivas Devadas, ”Design Space Exploration and Optimization of Path Oblivious RAM in Secure Processors,” In Proc. of the 40th Annual International Symposium on Computer Architecture, pp.  571-582, 2013.

%\noindent[4]M. Maas, E. Love, E. Stefanov, M. Tiwari, E. Shi, K. Asanovic,J. Kubiatowicz, and D. Song, “Phantom: Practical oblivious computationin a secure processor,” in Proceedings of the 2013 ACM SIGSACconference on Computer  communications security. ACM, 2013.

%\noindent[5]X. Zhang, G. Sun, C. Zhang, W. Zhang, Y. Liang, T. Wang, Y. Chen, and J. Di, “Fork path: improving efficiency of oram by removing redundant memory accesses,” in Proceedings of the 48th International Symposium on Microarchitecture. ACM, 2015.

%\noindent[6]E.Shi C.Fletcher L.Ren X.Yu E.Stefanov, M.vanDijk and S.Devadas,”Path oram: Anextremely simple oblivious ram protocol,” In Proc. of the 2013 ACM SIGSAC conference on computer  communications security,pp.299-310,2013 .

\begin{thebibliography}{9}
\bibitem{a}
Mohmmad Saiful Islam, Mehmet Kuzu and Murat Kantarcioglu,”Access Pattern disclosure on Searchable Encryption:Ramification,Attack and Mitigation,”In Proc. of the 19th Network and Distributed System Security Symposium,2012.

\bibitem{b}
Benny Pinkas and Tzachy Reinman,"Oblivious RAM Revisited,"  In Proc. of the 30th Annual cryptography conference, pp.  502-519, 2010.

\bibitem{c}
Ling Ren, Xiangyao yu, Christopher W. Fletcher, Marten van Dijk and Srinivas Devadas, ”Design Space Exploration and Optimization of Path Oblivious RAM in Secure Processors,” In Proc. of the 40th Annual International Symposium on Computer Architecture, pp.  571-582, 2013.

\bibitem{d}
M. Maas, E. Love, E. Stefanov, M. Tiwari, E. Shi, K. Asanovic,J. Kubiatowicz, and D. Song, “Phantom: Practical oblivious computationin a secure processor,” in Proceedings of the 2013 ACM SIGSACconference on Computer  communications security. ACM, 2013.

\bibitem{e}
X. Zhang, G. Sun, C. Zhang, W. Zhang, Y. Liang, T. Wang, Y. Chen, and J. Di, “Fork path: improving efficiency of oram by removing redundant memory accesses,” in Proceedings of the 48th International Symposium on Microarchitecture. ACM, 2015.

\bibitem{f}
E.Shi C.Fletcher L.Ren X.Yu E.Stefanov, M.vanDijk and S.Devadas,”Path oram: Anextremely simple oblivious ram protocol,” In Proc. of the 2013 ACM SIGSAC conference on computer  communications security,pp.299-310,2013 .

\bibitem{g}
Christopher W. Fletcher, Ling Ren, Albert Kwon, Marten van Dijk and Srinivas Devasdas, ”Freecursive ORAM: [Nearly]Free Recursion and Integrity Verification for Position-based Oblivious RAM,” In Proc. of the 20th International Conference on Architectural Support for Programing Languages and Operating Systems, pp. 103-116, 2015. 
\end{thebibliography}




%実験結果1
%\begin{figure}[p]
 % \includegraphics[width=8.0cm]{h2.png}
 % \caption{各共有数における提案手法でのメモリアクセス数(h264ref)}
 % \label{trdses}
%\end{figure}

%\begin{figure}[p]
 % \includegraphics[width=8.0cm]{hm.png}
 % \caption{各共有数における提案手法でのメモリアクセス数(hmmer)}
 % \label{tresasx}
%\end{figure}

%\begin{figure}[p]
 % \includegraphics[width=8.0cm]{om.png}
 % \caption{各共有数における提案手法でのメモリアクセス数(omnetpp)}
 % \label{tdscres}
%\end{figure}

%\begin{figure}[p]
 % \includegraphics[width=8.0cm]{li.png}
 % \caption{各共有数における提案手法でのメモリアクセス数(libquantum)}
 % \label{trswes}
%\end{figure}

%\begin{figure}[p]
 % \includegraphics[width=8.0cm]{gc.png}
 % \caption{各共有数における提案手法でのメモリアクセス数(gcc)}
 % \label{gccres}
%\end{figure}




%実験結果2
\begin{comment}
\begin{figure}[p]
  \begin{tabular}{cc}
    \begin{minipage}[t]{0.45\hsize}
    \includegraphics[width=18.0cm]{h26.png}
    \caption{各ポジションマップ削減手法のメモリアクセス数(h264ref)}
    \label{tres}
    \end{minipage} \\


    \begin{minipage}[t]{0.45\hsize}
    \includegraphics[width=18.0cm]{hmm.png}
    \caption{各ポジションマップ削減手法のメモリアクセス数(hmmer)}
    \label{tareas}
    \end{minipage} \\


    \begin{minipage}[t]{0.45\hsize}
    \includegraphics[width=18.0cm]{omn.png}
    \caption{各ポジションマップ削減手法のメモリアクセス数(omnetpp)}
    \label{taraes}
    \end{minipage} \\
  \end{tabular}
\end{figure}

\clearpage
%%%%

\begin{figure}[p]
  \begin{tabular}{cc}
    \begin{minipage}[t]{0.45\hsize}
    \includegraphics[width=18.0cm]{lib.png}
    \caption{各ポジションマップ削減手法のメモリアクセス数(libquantum)}
    \label{taresas}
    \end{minipage} \\

    \begin{minipage}[t]{0.45\hsize}
    \includegraphics[width=18.0cm]{gca.png}
    \caption{各ポジションマップ削減手法のメモリアクセス数(gcc)}
    \label{taaresas}
    \end{minipage} 
  \end{tabular}
\end{figure}
\end{comment}


\end{document}
% end of file
